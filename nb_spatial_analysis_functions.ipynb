{"cells":[{"cell_type":"code","source":["import requests\n","import pandas as pd\n","import geopandas as gpd\n","import osmnx as ox\n","import h3pandas\n","import h3\n","from shapely import wkt\n","from shapely.geometry import Polygon, mapping, shape, Point\n","from shapely.wkt import dumps as shapely_to_wkt, loads as load_wkt\n","from azure.storage.blob import BlobServiceClient\n","import folium as fo\n","import numpy as np\n","from delta import *\n","from pyspark.sql import functions as F\n","from pyspark.sql.functions import udf, col, count, substring, to_json, lit, md5, pandas_udf, explode\n","from pyspark.sql.types import StructType, StructField, DoubleType, StringType, BooleanType\n","from pyspark.sql.window import Window\n","from pyproj import Transformer\n","from bs4 import BeautifulSoup"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":[],"state":"session_error","livy_statement_state":null,"session_id":null,"normalized_state":"session_error","queued_time":"2025-06-06T15:50:47.6235328Z","session_start_time":"2025-06-06T15:50:47.624402Z","execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"60b78ebf-b768-4b00-b8bb-e975cae29f2b"},"text/plain":"StatementMeta(, , -1, SessionError, , SessionError)"},"metadata":{}},{"output_type":"error","ename":"InvalidHttpRequestToLivy","evalue":"[TooManyRequestsForCapacity] This spark job can't be run because you have hit a spark compute or API rate limit. To run this spark job, cancel an active Spark job through the Monitoring hub, choose a larger capacity SKU, or try again later. HTTP status code: 430 {Learn more} HTTP status code: 430.","traceback":["InvalidHttpRequestToLivy: [TooManyRequestsForCapacity] This spark job can't be run because you have hit a spark compute or API rate limit. To run this spark job, cancel an active Spark job through the Monitoring hub, choose a larger capacity SKU, or try again later. HTTP status code: 430 {Learn more} HTTP status code: 430."]}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6dd2cd8f-212d-4049-8531-87fdd41e6f82"},{"cell_type":"code","source":["# Functions\n","h3_level = 9\n","transformer = Transformer.from_crs(\"EPSG:27700\", \"EPSG:4326\", always_xy=True)\n","\n","def lat_lng_to_h3(lat, lng, resolution=7):\n","    # Convert latitude/longitude to H3 index at the given resolution\n","    return h3.latlng_to_cell(lat, lng, resolution)\n","\n","def eas_nor_to_h3(eas, nor, resolution=7):\n","    # Convert latitude/longitude to H3 index at the given resolution\n","    lat_lng = convert_coordinates(eas,nor)\n","    lat = lat_lng[0]\n","    lng = lat_lng[1]\n","    return h3.latlng_to_cell(lat, lng, resolution)\n","\n","\n","def h3_to_geo(row):\n","    co = h3.cell_to_boundary (row.h3)\n","    return Polygon(co)\n","\n","def cell_to_shapely(h3_index):\n","    coords = h3.cell_to_boundary(h3_index)\n","    flipped = tuple(coord[::-1] for coord in coords)\n","    return Polygon(flipped)\n","\n","def coords_to_shape(row):\n","    cell = h3.latlng_to_cell(row.geometry.y, row.geometry.x, h3_level)\n","    coords = h3.cell_to_boundary(cell)\n","    flipped = tuple(coord[::-1] for coord in coords)\n","    return Polygon(flipped)\n","\n","# Combined function:\n","# This will get the lat/lon fro the table, convert to a geometry, match to a H3 cell, flip the cell coords and return a polygon\n","def lat_lng_to_h3_geom(row):\n","    latlon = h3.latlng_to_cell(row.geometry.y, row.geometry.x, h3_level)\n","    coords = h3.cell_to_boundary(latlon)\n","    flipped = tuple(coord[::-1] for coord in coords)\n","    return Polygon(flipped)\n","\n","# Define the UDF to convert Easting/Northing to Lat/Lng and return as a StructType\n","def convert_coordinates(easting, northing):\n","    # Define transformer from EPSG:27700 to EPSG:4326\n","    lng, lat = transformer.transform(easting, northing)\n","    return (float(lat), float(lng))\n","\n","def h3_center(h3_index):\n","    lat, long = h3.cell_to_latlng(h3_index)\n","    return (float(lat), float(long))\n","\n","def h3_to_geojson(h3_index):\n","\n","    polygon = h3.cell_to_boundary(h3_index)\n","    flipped = tuple(coord[::-1] for coord in polygon)\n","\n","    if flipped[0] != flipped[-1]:\n","        flipped = list(flipped)\n","        flipped.append(flipped[0])\n","\n","    feature = {\n","        \"type\": \"Feature\",\n","        \"geometry\": {\n","            \"type\": \"Polygon\",\n","            \"coordinates\": [flipped]\n","        },\n","        \"properties\": {\n","            \"h3_id\": h3_index\n","        }\n","    }\n","  \n","    return json.dumps(feature)\n","\n","def h3_to_wkt_polygon(h3_index):\n","\n","    polygon = h3.cell_to_boundary(h3_index)\n","    flipped = tuple(coord[::-1] for coord in polygon)\n","\n","    if flipped[0] != flipped[-1]:\n","        flipped = list(flipped)\n","        flipped.append(flipped[0])\n","\n","    wkt = \"POLYGON((\" + \",\".join([f\"{x} {y}\" for x, y in flipped]) + \"))\"\n","    return wkt\n","\n","def get_parent_h3_index(h3_index, res):\n","    return h3.cell_to_parent(h3_index, res)\n","\n","def lat_lng_to_h3_vectorized(lats,lons,resolution=7):\n","    h3_indices = np.vectorize(lambda lat, lon: h3.latlng_to_cell(lat,lon,resolution))(lats,lons)\n","    return h3_indices\n","\n","def make_polygon_udf(broadcasted_polygons):\n","    def is_outside(lat, lon):\n","        point = Point(lon, lat)  # Shapely uses (x, y) -> (lon, lat)\n","        for poly in broadcasted_polygons.value:\n","            if poly.contains(point):\n","                return False\n","        return True\n","\n","    return udf(is_outside, BooleanType())\n","\n","def get_polygon_wkt(lat, lon):\n","    pt = Point(lon, lat)\n","    for poly_wkt in broadcast_polygons.value:\n","        polygon = load_wkt(poly_wkt)\n","        if polygon.contains(pt):\n","            return poly_wkt\n","    return None\n","\n","def lat_long_to_wkt(lat, lon):\n","    if lat is None or lon is None:\n","        return None\n","    return f\"POINT({lon} {lat})\"  # Note: WKT POINT is \"POINT(lon lat)\"\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"06262042-898a-490b-ac16-321ca8cb3881"},{"cell_type":"code","source":["schema = StructType([\n","    StructField(\"latitude\", DoubleType()),\n","    StructField(\"longitude\", DoubleType())\n","])"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"12117b70-29f1-46c3-b1b4-d221604391c3","normalized_state":"finished","queued_time":"2025-05-14T14:48:13.1394672Z","session_start_time":null,"execution_start_time":"2025-05-14T14:48:17.1406585Z","execution_finish_time":"2025-05-14T14:48:17.4040744Z","parent_msg_id":"5d53e655-97d2-4695-b970-c79d34921e0f"},"text/plain":"StatementMeta(, 12117b70-29f1-46c3-b1b4-d221604391c3, 7, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"05cef14f-45ca-4dc4-bbac-ee7b15bb48b1"},{"cell_type":"code","source":["@pandas_udf(schema)\n","def convert_bng_to_wgs84(easting: pd.Series, northing: pd.Series) -> pd.DataFrame:\n","    lons, lats = transformer.transform(easting.values, northing.values)\n","    return pd.DataFrame({\n","        \"longitude\": lons,\n","        \"latitude\": lats\n","    })\n","\n","@pandas_udf(StringType())\n","def lat_long_to_h3_index(lat: pd.Series, long: pd.Series, resolution: pd.Series) -> pd.Series:\n","    return pd.Series([\n","            h3.latlng_to_cell(lat_val, long_val, int(res)) \n","            for lat_val, long_val, res in zip(lat, long, resolution)\n","    ])\n","\n","def make_point_in_polygon_udf(broadcasted_polygons):\n","    \"\"\"\n","    Returns a Pandas UDF that checks if a (lat, lon) point is inside any polygon\n","    from the broadcasted list of polygons.\n","    \"\"\"\n","    @pandas_udf(BooleanType())\n","    def is_inside(lat: pd.Series, lon: pd.Series) -> pd.Series:\n","        polygons = broadcasted_polygons.value\n","        points = [Point(lon_, lat_) for lon_, lat_ in zip(lon, lat)]\n","        return pd.Series([\n","            any(poly.contains(point) for poly in polygons)\n","            for point in points\n","        ])\n","   \n","    return is_inside\n","\n","def add_matched_columns(df, udf_result, col_names):\n","    for col_name in col_names:\n","        df = df.withColumn(col_name, udf_result[col_name])\n","    return df\n","\n","def extract_polygons_from_gdf(gdf: gpd.GeoDataFrame):\n","    gdf = gdf.to_crs(\"EPSG:4326\")\n","    return_columns = [col for col in gdf.columns if col != \"geometry\"]\n","    return [\n","        {**{col: str(row[col]) for col in return_columns}, \"geometry\": row.geometry}\n","        for _, row in gdf.iterrows()\n","    ], return_columns\n","\n","def make_polygon_match_udf(broadcasted_polygons, columns_to_return: list):\n","    # Always convert geometry to WKT if requested\n","    schema = StructType([\n","        StructField(col, StringType()) for col in columns_to_return\n","    ])\n","\n","    @pandas_udf(schema)\n","    def match_polygon(lat: pd.Series, lon: pd.Series) -> pd.DataFrame:\n","        polygons = broadcasted_polygons.value\n","        points = [Point(lon_, lat_) for lon_, lat_ in zip(lon, lat)]\n","\n","        results = []\n","        for pt in points:\n","            match = next((rec for rec in polygons if rec[\"geometry\"].contains(pt)), None)\n","            if match:\n","                row = {}\n","                for col in columns_to_return:\n","                    if col == \"geometry_wkt\":\n","                        row[col] = match[\"geometry\"].wkt\n","                    else:\n","                        row[col] = match.get(col, \"\")\n","                results.append(row)\n","            else:\n","                results.append({col: \"\" for col in columns_to_return})\n","\n","        return pd.DataFrame(results)\n","\n","    return match_polygon"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","session_id":"12117b70-29f1-46c3-b1b4-d221604391c3","normalized_state":"finished","queued_time":"2025-05-14T15:03:08.7424395Z","session_start_time":null,"execution_start_time":"2025-05-14T15:03:08.7435365Z","execution_finish_time":"2025-05-14T15:03:09.0473104Z","parent_msg_id":"3cd40396-f98f-4beb-82bb-c96dcef6bdd1"},"text/plain":"StatementMeta(, 12117b70-29f1-46c3-b1b4-d221604391c3, 10, Finished, Available, Finished)"},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"008ec7de-72f7-4067-9d3e-a21c8bfe80d5"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"environment":{"environmentId":"d484b47b-e647-4d49-b319-87056891cb74","workspaceId":"5beeb403-23b8-40c0-ad70-94268c0a82ff"}}},"nbformat":4,"nbformat_minor":5}